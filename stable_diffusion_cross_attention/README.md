We use the code for [prompt-to-prompt](https://prompt-to-prompt.github.io/) to analyze the attention in stable diffusion.


## Visualize Cross-Attention 

The way to visualize cross-attention between word tokens and image feature map is shown as follows


<img src="attention_vis_process.jpeg" alt="drawing" style="width:400px;"/>

Visualization exampels:
![attenion vis example1](attention_vis_example1.jpg)
![attenion vis process](attention_vis_example1.jpeg)